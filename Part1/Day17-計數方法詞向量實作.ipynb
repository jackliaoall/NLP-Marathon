{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 瞭解如何使用計數方法詞向量與SVD\n",
    "\n",
    "再將文字資料輸入模型進行自然語言任務之前，其中一項重要的前處理即為將字詞向量化(詞嵌入word embedding)。 而將詞向量化的方法有很多，這裡我們會著重在介紹如何使用計數方法來將字詞向量化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字詞前處理\n",
    "\n",
    "在進行字詞向量化之前，我們需要針對文本資料進行前置處理，將**文本資料分割成字詞(斷詞)**，再將分割後的**字詞轉換成字詞ID清單**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed corpus: [[4 0 6 2 3 0 1 5]] \n",
      " word2idx: {'say': 0, 'hello': 1, 'and': 2, 'i': 3, 'you': 4, '.': 5, 'goodbye': 6} \n",
      " idx2word: {0: 'say', 1: 'hello', 2: 'and', 3: 'i', 4: 'you', 5: '.', 6: 'goodbye'}\n"
     ]
    }
   ],
   "source": [
    "#導入會使用的library\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "#定義前處理函式\n",
    "def preprocess(corpus: List[str], only_word: bool = False):\n",
    "    '''Function to do preprocess of input corpus\n",
    "    Parameters\n",
    "    -----------\n",
    "    corpus: str\n",
    "        input corpus to be processed\n",
    "    only_word: bool\n",
    "        whether to filter out non-word\n",
    "    '''\n",
    "    word_dic = set()\n",
    "    processed_sentence = []\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        #將所有字詞轉為小寫\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        #移除標點符號(可以依據使用狀況決定是否要移除標點符號)\n",
    "        if only_word:\n",
    "            pattern = r'[^\\W_]+'\n",
    "            sentence = re.findall(pattern, sentence)\n",
    "        else:\n",
    "            punctuation_list = ['.', ',', '!', '?']\n",
    "            for pun in punctuation_list:\n",
    "                sentence = sentence.replace(pun, ' '+pun)\n",
    "            sentence = sentence.split(' ')\n",
    "        \n",
    "        #添加字詞到字典中\n",
    "        word_dic |= set(sentence)\n",
    "        processed_sentence.append(sentence)\n",
    "    \n",
    "    \n",
    "    #建立字詞ID清單\n",
    "    word2idx = dict()\n",
    "    idx2word = dict()\n",
    "    for word in word_dic:\n",
    "        if word not in word2idx:\n",
    "            idx = len(word2idx)\n",
    "            word2idx[word] = idx\n",
    "            idx2word[idx] = word\n",
    "\n",
    "    #將文本轉為ID型式\n",
    "    id_mapping = lambda x: word2idx[x]\n",
    "    \n",
    "    corpus = np.array([list(map(id_mapping, sentence)) for sentence in processed_sentence])\n",
    "\n",
    "    return corpus, word2idx, idx2word\n",
    "\n",
    "#定義簡易文本資料(使用Ch17講義中的例子)\n",
    "corpus = ['You say goodbye and I say hello.']\n",
    "\n",
    "processed_corpus, word2idx, idx2word = preprocess(corpus)\n",
    "print(f'Processed corpus: {processed_corpus} \\n word2idx: {word2idx} \\n idx2word: {idx2word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共現矩陣\n",
    "將轉化處理過的文本資料轉化為共現矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 1, 0, 1, 0],\n",
       "       [2, 0, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定義共現矩陣函式\n",
    "def create_co_matrix(corpus: np.ndarray, vocab_size: int, window_size: int=1):\n",
    "    '''\n",
    "    '''\n",
    "    # initialize co-occurrence matrix\n",
    "    co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence_size = len(sentence)\n",
    "    \n",
    "        for idx, word_id in enumerate(sentence):\n",
    "            for i in range(1, window_size+1):\n",
    "                left_idx = idx - i\n",
    "                right_idx = idx + i\n",
    "\n",
    "                if left_idx >= 0:\n",
    "                    left_word_id = sentence[left_idx]\n",
    "                    co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "                if right_idx < sentence_size:\n",
    "                    right_word_id = sentence[right_idx]\n",
    "                    co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix\n",
    "\n",
    "co_matrix = create_co_matrix(processed_corpus, len(word2idx), 2)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 1, 0, 1, 0],\n",
       "       [2, 0, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義共現矩陣函式\n",
    "# method two\n",
    "\n",
    "def create_co_matrix(corpus: np.ndarray, vocab_size: int, window_size: int=1):\n",
    "    '''\n",
    "    '''\n",
    "    # initialize co-occurrence matrix\n",
    "    co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence_size = len(sentence)\n",
    "    \n",
    "        for idx, word_id in enumerate(sentence):\n",
    "            left_idx = idx - window_size if idx - window_size >= 0 else 0\n",
    "            context_ids = sentence[left_idx:idx]\n",
    "            \n",
    "            for left_i, left_id in enumerate(context_ids):\n",
    "                co_matrix[word_id, left_id] += 1\n",
    "                co_matrix[left_id, word_id] += 1\n",
    "\n",
    "    return co_matrix\n",
    "\n",
    "co_matrix = create_co_matrix(processed_corpus, len(word2idx), 2)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量間相似度\n",
    "比較轉換為向量的字詞的方法有很多種，其中當要表示字詞的相似度時，最常使用的方法為餘弦相似度 (Cosine Similarity)\n",
    "\n",
    "$$\n",
    "sim(x,y) = \\frac{xy}{||x||||y||}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067691154799"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義餘弦相似度\n",
    "def cos_similarity(x: np.ndarray, y: np.ndarray, eps: float=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x**2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y**2)) + eps)\n",
    "    \n",
    "    return np.dot(nx,ny)\n",
    "\n",
    "# calculate the similarity between I and you\n",
    "cos_similarity(co_matrix[word2idx['i']], co_matrix[word2idx['you']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立可供查詢相似度的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入字詞，查詢與此字詞top_n相似的結果\n",
    "def top_k_similarity(query: str, word2idx: dict, idx2word: dict, word_matrix: np.ndarray, top_k: int=3):\n",
    "    # handle the situation of query word not in corpus\n",
    "    if query not in word2idx:\n",
    "        raise ValueError(f\"{query} is not found in input dictionary\")\n",
    "        \n",
    "    print(f\"[query] : {query}\")\n",
    "    query_id = word2idx[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # calculate cosine similarity\n",
    "    similarity_scores = np.zeros(len(word2idx))\n",
    "    for i in range(len(word2idx)):\n",
    "        similarity_scores[i] = cos_similarity(query_vec, word_matrix[i])\n",
    "\n",
    "    # remove query word\n",
    "    similarity_scores = np.delete(similarity_scores, query_id)\n",
    "    filter_word2idx = dict([(k, v) for k, v in word2idx.items() if k != query])\n",
    "    filter_idx2word = dict([(k, v) for k, v in idx2word.items() if k != query_id])\n",
    "    \n",
    "    # sorting by similarity score\n",
    "    top_k_idx = (-similarity_scores).argsort()[:top_k]\n",
    "    top_k_word = [filter_idx2word[word_idx] for word_idx in filter_idx2word]\n",
    "    \n",
    "    return dict(zip(top_k_word, similarity_scores[top_k_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query] : you\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'say': 0.7071067691154799,\n",
       " 'hello': 0.7071067691154799,\n",
       " 'and': 0.7071067691154799}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_similarity('you', word2idx, idx2word, co_matrix, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正向點間互資訊(PPMI)\n",
    "由於共生矩陣在高頻字上的缺陷，而PMI中加入了兩字詞共同出現的機率與各自出現的機率的關係，以此解決高頻詞在共生矩陣上的缺陷。\n",
    "而PPMI即將PMI內會產生負值的情況排除(若出現負值則賦予0)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&PMI(x,y) = log_2\\frac{P(x,y)}{P(x)P(y)} = log_2\\frac{C(x,y)N}{C(x)C(y)} \\\\\n",
    "&PPMI(x,y) = max(0,PMI(x,y))\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義正向點間互資訊\n",
    "\n",
    "def ppmi(co_matrix: np.ndarray, eps: float=1e-8, verbose: bool=False):\n",
    "    M = np.zeros_like(co_matrix, dtype=np.float32)\n",
    "    N = np.sum(co_matrix)\n",
    "    S = np.sum(co_matrix, axis=0)\n",
    "    total = co_matrix.shape[0]*co_matrix.shape[1]\n",
    "\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(co_matrix.shape[0]):\n",
    "        for j in range(co_matrix.shape[1]):\n",
    "            pmi = np.log2(co_matrix[i, j]*N / (S[i]*S[j] + eps))\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % 10 == 0 or cnt == total:\n",
    "                    print(f\"{cnt}/{total} Done\")\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/49 Done\n",
      "20/49 Done\n",
      "30/49 Done\n",
      "40/49 Done\n",
      "49/49 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Documents/Coding/Python/Deep_Learning_Implement/Pytorch_Implementation/pytorch_env/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log2\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.8073549, 0.       , 0.8073549, 1.8073549, 0.       ,\n",
       "        0.8073549],\n",
       "       [0.8073549, 0.       , 0.       , 0.       , 0.       , 2.807355 ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , 1.8073549, 0.       , 0.       ,\n",
       "        1.8073549],\n",
       "       [0.8073549, 0.       , 1.8073549, 0.       , 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [1.8073549, 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 2.807355 , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.8073549, 0.       , 1.8073549, 0.       , 0.       , 0.       ,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ppmi = ppmi(co_matrix, verbose=True)\n",
    "output_ppmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "觀察上面的PPMI輸出矩陣，可以發現大部分的元素都為0(稀疏矩陣)，因此可以發現此矩陣包含了許多無法提供訊息的元素，利用奇異值分解，將矩陣降維，並保存重要的資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello in co-occurrence matrix: [0 1 0 1 1 0 1]\n",
      "hello in PPMI: [0.        0.8073549 0.        0.8073549 1.8073549 0.        0.8073549]\n",
      "hello in SVD: [ 5.9763640e-01  2.2204460e-16 -1.1379786e-15  1.8023790e-01\n",
      "  1.1102230e-16  7.8124583e-01  8.3266727e-17]\n"
     ]
    }
   ],
   "source": [
    "# 使用np的linalg.svd對PPMI矩陣進行奇異值分解\n",
    "\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(output_ppmi)\n",
    "\n",
    "# 使用SVD將將原本的稀疏向量轉變為稠密向量\n",
    "print(f'hello in co-occurrence matrix: {co_matrix[0]}')\n",
    "print(f\"hello in PPMI: {output_ppmi[0]}\")\n",
    "print(f\"hello in SVD: {U[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.6359119e-18  8.0735499e-01 -2.4116074e-17  8.0735505e-01\n",
      "   1.8073549e+00  5.2875817e-17  8.0735505e-01]\n",
      " [ 8.0735511e-01 -1.1181055e-15 -1.7773232e-08 -5.7231449e-16\n",
      "   1.5899218e-15  2.8073552e+00 -5.7231449e-16]\n",
      " [-1.5804978e-17 -1.0274201e-07  4.4801942e-17  1.8073548e+00\n",
      "   2.5773190e-08  1.0876119e-16  1.8073548e+00]\n",
      " [ 8.0735487e-01  4.6341675e-16  1.8073548e+00  3.1999769e-16\n",
      "  -5.9917708e-16  3.8959115e-08  3.2961538e-16]\n",
      " [ 1.8073549e+00  1.8563789e-17 -5.7845853e-09 -1.1394344e-16\n",
      "   3.0448291e-16  2.0239966e-08 -1.1394344e-16]\n",
      " [-6.3467749e-24  2.8073549e+00 -4.1738390e-16  1.0483901e-07\n",
      "   5.5473514e-08 -3.1192266e-16  1.0483901e-07]\n",
      " [ 8.0735487e-01  3.7803017e-16  1.8073548e+00  5.9643534e-16\n",
      "  -8.4655554e-16  3.8959115e-08  5.8681760e-16]]\n",
      "[[0.        0.8073549 0.        0.8073549 1.8073549 0.        0.8073549]\n",
      " [0.8073549 0.        0.        0.        0.        2.807355  0.       ]\n",
      " [0.        0.        0.        1.8073549 0.        0.        1.8073549]\n",
      " [0.8073549 0.        1.8073549 0.        0.        0.        0.       ]\n",
      " [1.8073549 0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        2.807355  0.        0.        0.        0.        0.       ]\n",
      " [0.8073549 0.        1.8073549 0.        0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# 檢查分解是否正確\n",
    "A = U @ np.diag(S) @ V\n",
    "print(A)\n",
    "print(output_ppmi)\n",
    "# 可以發先做完SVD得結果跟原來的output_ppmi是相同的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1680453e+00 3.1680453e+00 2.7029872e+00 2.7029872e+00 1.5144811e+00\n",
      " 1.5144811e+00 9.2750728e-18]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.9782813e-01,  3.3306691e-16, -3.3306691e-16, -6.8039632e-01,\n",
       "         5.3779924e-01,  0.0000000e+00],\n",
       "       [ 1.6653345e-16, -4.3631220e-01, -5.0878286e-01,  2.2204460e-16,\n",
       "        -2.2204460e-16,  2.2532563e-01],\n",
       "       [-3.6082248e-16, -7.0923710e-01,  6.8392676e-01, -3.3306691e-16,\n",
       "         0.0000000e+00,  1.7095888e-01],\n",
       "       [ 1.6653345e-16, -3.4094876e-01, -1.2051624e-01,  2.7755576e-16,\n",
       "        -1.1102230e-16, -9.3232495e-01],\n",
       "       [-5.5511151e-17, -4.3631220e-01, -5.0878286e-01, -5.5511151e-17,\n",
       "         1.6653345e-16,  2.2532563e-01],\n",
       "       [-6.2848860e-01,  0.0000000e+00,  0.0000000e+00,  7.1033454e-01,\n",
       "         3.1690210e-01,  0.0000000e+00],\n",
       "       [-5.9763640e-01,  1.3215010e-16, -1.7505738e-16, -1.8023790e-01,\n",
       "        -7.8124583e-01, -1.3938715e-16]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以發現前六個奇異值就佔了絕大多數的奇異值\n",
    "print(S)\n",
    "\n",
    "# 可以取前六個維度當作降為的詞向量\n",
    "U_reduce = U[:, 0:6]\n",
    "U_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 將詞向量降為二維方便視覺化\n",
    "U_visualization = U[:, 0:2]\n",
    "\n",
    "# visualization\n",
    "for word, word_id in word2idx.items():\n",
    "    plt.annotate(word, (U_reduce[word_id, 0], U_reduce[word_id, 1]))\n",
    "    \n",
    "plt.scatter(U_reduce[:, 0], U_reduce[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
