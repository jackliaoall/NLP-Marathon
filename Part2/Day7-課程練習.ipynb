{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Module\n",
    "* Base class for all neural network modules\n",
    "* 只要在nn.Module的子類中定義了forward函數，backward函數就會被自動實現（利用Autograd）\n",
    "* nn.Conv2d 本身也是nn.Module的類別(此時我們可以先不用理解nn.Conv2D做了什麼，只需了解其包含一些參數與操作)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 實踐 forward propagation \n",
    "* 為什麼不應該直接call model.forward : https://discuss.pytorch.org/t/any-different-between-model-input-and-model-forward-input/3690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(1,1,124,124)\n",
    "output = model(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看 model 底下的 modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model.modules 遞迴的列出所有的 modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      ")\n",
      "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "for module in model.modules():\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model.children 只列出第一層的子 modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "for module in model.children():\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看 model 內的 parameters (torch.nn.parameter.Parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .named_parameters\n",
    "* named_parameters會列出每個nn.Module底下parameters 的名字,數值\n",
    "* 同時可以查看 requires_grad是否開啟(for backpropagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight True\n",
      "conv1.bias True\n",
      "conv2.weight True\n",
      "conv2.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name,param.requires_grad)\n",
    "    #param.requires_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .parameters\n",
    "* 不會印出名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20, 1, 5, 5]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20, 20, 5, 5]) True\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20]) True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(type(param),param.shape, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 計算模型可訓練參數總量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共參數量： 10540\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('總共參數量：' ,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(1,1,124,124)\n",
    "output = model(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 確認 requires_grad為 True (default 就是 True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight True\n",
      "conv1.bias True\n",
      "conv2.weight True\n",
      "conv2.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 此時還沒做backpropagation，parameters沒有gradient value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 執行backward，完成後就能看到每個parameters底下的gradient value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-3.9841e+02,  6.0265e+01,  8.3941e+02, -4.0811e+02, -5.0551e+02],\n",
      "          [-4.5694e+01,  1.9287e+02,  6.8446e+02,  7.0936e+02, -4.9671e+02],\n",
      "          [ 1.2062e+02, -4.9557e+02,  2.0279e+02,  1.7787e+00,  2.4515e+02],\n",
      "          [-3.5738e+02, -6.4618e+02,  3.5662e+02, -3.4831e+02, -2.6697e+02],\n",
      "          [-3.5568e+02,  5.9962e+02, -2.4759e+02, -7.1152e+02,  7.8287e+02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2128e+02, -3.4191e+01,  1.0238e+02, -4.2600e+02,  1.0047e+01],\n",
      "          [-2.0660e+02, -1.1541e+02,  1.8130e+02,  2.6142e+02, -3.5687e+02],\n",
      "          [ 3.4553e+02, -2.0279e+02,  3.9684e+02,  1.5776e+02,  6.0539e+02],\n",
      "          [ 4.3211e+02,  3.0171e+02, -1.8974e+02, -6.9497e+02, -4.6586e+02],\n",
      "          [ 1.3787e+02,  1.7408e+02, -5.6302e+02, -2.7836e+02,  4.5642e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4504e+01,  3.9325e+01, -3.1536e+01, -2.3886e+01, -4.0643e+02],\n",
      "          [-3.9561e+02, -1.3097e+02, -1.9010e+02,  4.3633e+02, -4.3261e+02],\n",
      "          [ 2.1376e+02, -1.9404e+02,  4.1607e+02,  1.9061e+01, -1.9603e+01],\n",
      "          [ 8.1035e+01, -3.5809e+02, -1.4257e+02, -3.0016e+02,  3.1148e+01],\n",
      "          [ 3.0870e+02, -2.7793e+02, -4.1842e+02,  7.5007e+01,  9.5174e+01]]],\n",
      "\n",
      "\n",
      "        [[[-4.8316e+02,  8.1953e+02, -3.5494e+02, -1.4670e+02, -6.1854e+01],\n",
      "          [-6.5589e+02,  4.6617e+02,  1.0782e+02, -2.9059e+02,  7.4733e+02],\n",
      "          [ 5.7372e+02, -9.2899e+02, -4.4612e+02, -8.6061e+02,  4.0491e+02],\n",
      "          [ 5.5937e+02,  9.7549e+01, -6.7416e+02,  3.6108e+02,  7.9739e+02],\n",
      "          [ 2.0275e+02, -3.5695e+02, -1.9950e+02, -2.1187e+02, -3.3403e+02]]],\n",
      "\n",
      "\n",
      "        [[[-5.9295e+02, -1.1501e+03, -6.9574e+02,  9.2151e+02, -9.1250e+01],\n",
      "          [-1.3914e+03,  6.2975e+02, -5.6667e+02, -1.1026e+03,  6.9768e+02],\n",
      "          [-1.4989e+02, -9.4112e+02,  5.5938e+00, -6.4102e+02, -7.0355e+02],\n",
      "          [ 6.9500e+01,  5.4665e+01, -1.2567e+03,  1.0361e+03, -5.0000e+02],\n",
      "          [ 1.1163e+03,  1.0563e+03, -7.7782e+02,  1.2085e+03,  9.1418e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2590e+02,  5.6730e+01,  5.1008e+01,  1.3794e+02,  8.9336e+01],\n",
      "          [ 2.4889e+02,  1.5694e+02, -1.8455e+02, -1.3612e+02, -1.1684e+00],\n",
      "          [ 2.0472e+02,  1.4088e+02,  2.6967e+01,  3.9003e+02,  2.4553e+02],\n",
      "          [-3.4437e+01,  2.5744e+02, -3.5724e+02, -5.0794e+02, -1.4522e+02],\n",
      "          [ 1.5892e+02, -3.4485e+01,  5.5165e+01, -1.1916e+02, -1.5013e+01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2858e+01,  1.9815e+02,  5.9262e+01,  2.8329e+02, -1.0363e+02],\n",
      "          [-5.2627e+01, -6.4147e+00, -1.4539e+01,  1.5494e+02, -1.2250e+02],\n",
      "          [-1.6296e+02,  1.8825e+02, -2.9636e+02,  1.6112e+02,  3.2665e+02],\n",
      "          [-2.1301e+02,  6.2603e+01, -1.8804e+01,  4.4387e+02, -3.8859e+02],\n",
      "          [-2.4703e+02,  5.8117e+01,  2.2479e+02, -2.6004e+02, -2.4334e+02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8490e+02, -1.0441e+03, -3.0382e+02, -4.2191e+02, -9.5482e+02],\n",
      "          [ 9.5490e+01,  1.5021e+02, -1.5136e+03,  6.1017e+02, -8.5644e+02],\n",
      "          [ 3.6308e+02,  1.1407e+03, -1.1020e+03, -1.1475e+03,  5.7132e+02],\n",
      "          [ 4.6661e+02, -1.1413e+03,  4.9427e+02, -4.0373e+02,  1.0824e+03],\n",
      "          [ 6.6948e+02,  1.0988e+03, -6.9077e+02, -1.1333e+03,  1.0635e+03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1043e+02, -1.0170e+03,  8.7100e+02, -1.1207e+03,  3.1558e+02],\n",
      "          [ 6.2542e+02, -2.5600e+02, -1.1429e+03,  3.8296e+02,  1.2968e+02],\n",
      "          [ 7.8270e+02,  6.3460e+02,  3.9375e+02, -9.3603e+02, -7.9875e+02],\n",
      "          [ 9.2697e+02,  9.4621e+02,  6.8072e+02,  1.2253e+03,  3.5777e+02],\n",
      "          [-1.3547e+03, -3.8707e+02,  7.7695e+02, -5.0793e+02,  9.6003e+02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3936e+03,  1.4764e+03,  6.2831e+02, -8.8942e+02,  5.2191e+02],\n",
      "          [ 1.8789e+03,  1.2094e+03,  1.8004e+03,  1.4706e+03, -3.3903e+02],\n",
      "          [-1.4024e+03,  1.8242e+02, -1.9230e+03, -1.8785e+02, -8.2139e+02],\n",
      "          [-9.7478e+02, -2.0292e+03,  1.0189e+03, -1.1762e+03, -2.0644e+03],\n",
      "          [-7.8126e+02,  5.5454e+01,  1.6971e+02, -1.8917e+03,  1.5378e+03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6471e+02,  2.6388e+02, -2.9136e+02,  9.4346e+01, -7.2149e+02],\n",
      "          [-1.7245e+02, -7.9502e+02, -3.1665e+02,  9.7415e+01,  5.9883e+02],\n",
      "          [-1.5818e+02, -1.2742e+02, -4.5022e+02,  4.9478e+02, -1.1163e+03],\n",
      "          [-7.3405e+02,  1.5669e+01,  2.0221e+02,  3.1199e+02, -4.4391e+02],\n",
      "          [-2.6105e+02, -7.1305e+02, -5.5954e+02,  4.6929e+01,  2.9883e+02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8160e+02,  5.8066e+01,  1.4220e+01, -2.7253e+02,  4.3166e+02],\n",
      "          [-3.2659e+02, -2.0915e+02,  7.9201e+01,  6.3208e+01,  2.6661e+00],\n",
      "          [-2.8290e+02,  2.0185e+02,  4.1065e+01,  2.7287e+02, -1.9264e+02],\n",
      "          [-1.5409e+02,  2.0703e+02, -5.5202e+01, -2.3867e+02,  3.3174e+02],\n",
      "          [-3.3224e+02, -1.7581e+02,  3.8625e+02,  8.4218e+01,  9.6583e+01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7433e+02,  2.1783e+02,  2.3552e+02,  4.8305e+01, -1.6249e+02],\n",
      "          [-1.1077e+02, -2.3355e+02,  2.2559e+02,  1.0320e+01,  5.3534e+01],\n",
      "          [ 2.4487e+02,  2.3933e+02,  1.4774e+02,  2.0921e+02,  7.0170e+01],\n",
      "          [-3.6541e+02,  1.1029e+02, -1.6392e+02, -1.5357e+02, -1.5648e+02],\n",
      "          [ 2.1825e+02, -2.3680e+02,  1.9590e+02,  1.1682e+02, -2.0897e+01]]],\n",
      "\n",
      "\n",
      "        [[[-4.4771e+02, -1.0180e+03, -5.5348e+02,  3.2923e+02, -3.2015e+02],\n",
      "          [ 1.2188e+03, -5.0163e+02, -2.4978e+02,  1.7878e+02,  3.1700e+02],\n",
      "          [ 9.1699e+02, -9.1378e+02, -4.5336e+02,  2.8695e+02, -4.7125e+02],\n",
      "          [-6.0237e+02,  5.3792e+02, -6.5721e+02, -1.1190e+02,  7.7836e+02],\n",
      "          [ 7.7122e+02, -1.3686e+03, -7.5168e+02,  9.2578e+02, -1.4655e+02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0055e+03, -7.7776e+02, -3.2200e+02, -1.0033e+02, -8.1562e+02],\n",
      "          [ 6.4432e+02,  3.9492e+02, -1.1210e+02,  1.7503e+02,  6.2081e+02],\n",
      "          [-7.1007e+02,  4.0389e+02,  1.1703e+02,  7.2595e+02, -3.9831e+01],\n",
      "          [ 6.1996e+02,  6.0844e+02, -3.9072e+02,  2.6809e+02,  2.9077e+01],\n",
      "          [ 2.1863e+02, -5.9219e+02,  9.0780e+02,  5.1908e+02,  8.9797e+02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1830e+03, -7.3598e+02, -1.5956e+03,  5.6470e+02, -3.6626e+02],\n",
      "          [ 1.2859e+03, -3.5558e+01, -1.0464e+03,  2.3501e+02,  7.7558e+02],\n",
      "          [-1.2738e+03, -6.5556e+02, -9.5586e+02,  6.0110e+02, -1.5809e+03],\n",
      "          [-8.7484e+02, -7.7109e+02,  5.9955e+02, -1.2005e+03,  3.0298e+02],\n",
      "          [ 2.0042e+01,  4.3093e+02, -3.3541e+01,  3.4752e+02, -1.5294e+03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1582e+02, -1.4828e+03,  3.2644e+01,  8.1856e+02, -1.0944e+03],\n",
      "          [ 1.3495e+03,  2.5356e+02, -8.7304e+02,  5.7784e+02,  1.1276e+02],\n",
      "          [-4.7150e+02, -5.8084e+02, -1.5708e+03,  9.0210e+02,  1.0891e+03],\n",
      "          [ 9.9735e+02,  4.4119e+02, -1.4190e+03, -7.3039e+02,  1.6701e+02],\n",
      "          [-1.4691e+03, -7.4515e+02,  4.6450e+02, -1.7169e+02, -1.1305e+03]]],\n",
      "\n",
      "\n",
      "        [[[-6.5979e+02, -4.7612e+02, -5.9762e+02,  4.4434e+02,  2.5056e+02],\n",
      "          [ 3.8547e+02, -5.5561e+02,  4.4789e+01, -3.1488e+02, -2.7678e+02],\n",
      "          [-6.1217e+01,  7.5061e+02, -4.1358e+02,  6.1400e+02, -3.8041e+02],\n",
      "          [-4.8397e+02, -3.0938e+02,  9.3964e+01,  1.5840e+02,  3.6505e+02],\n",
      "          [-4.8326e+02,  2.0312e+02, -5.3036e+02, -2.5897e+02, -3.9592e+02]]],\n",
      "\n",
      "\n",
      "        [[[-8.2659e+02,  1.2635e+03, -1.0159e+03,  1.1394e+02,  8.2630e+02],\n",
      "          [ 5.8605e+02, -3.1513e+02,  5.0024e+02,  5.3747e+02, -1.2651e+02],\n",
      "          [ 2.1416e+02, -1.0730e+03, -1.0846e+03,  2.3772e+02,  2.6349e+02],\n",
      "          [ 1.0159e+03,  9.2553e+02,  1.0592e+03,  4.2652e+02,  3.9947e+02],\n",
      "          [ 8.1151e+02,  1.3212e+03,  4.7860e+02,  1.2579e+03,  1.9214e+02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8430e+02, -2.0491e+03, -1.2231e+03,  1.3715e+03,  3.1083e+02],\n",
      "          [ 1.1973e+03,  1.9751e+02, -4.4202e+02, -1.2434e+02, -1.8168e+03],\n",
      "          [-1.0508e+03,  8.6457e+02, -1.3679e+03,  8.1564e+02, -1.5805e+03],\n",
      "          [-5.8289e+01,  4.2285e+02,  2.5150e+02,  1.8856e+03,  2.0260e+03],\n",
      "          [-6.7361e+02,  4.1407e+02, -3.9531e+02, -1.8202e+03, -1.4954e+03]]]])\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 當我們把 parameters 的 requires_grad關閉時，就無法成功的完成backward\n",
    "* 什麼時候會關閉requires_grad關閉時？ prediction (inference)的階段\n",
    "* 設定 requires_grad = True 是為了之後要做 backpropagation，在計算每個paramters的 gradient時，我們在forward propagation時需要保留額外的訊息(根據chain rule)，這會導致記憶體使用量上升與計算速度下降，然而只有在 training 階段時我們材需要做backpropagation，在 prediction (inference)的階段，我們則可以設定 requires_grad = False 來提升速度與降低記憶體使用量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(1,1,124,124)\n",
    "output = model(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-d36a7f9dc350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "output.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with torch.no_grad()\n",
    "* 此行底下的requires_grad都會關閉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-1f483c7eca92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "with torch.no_grad():\n",
    "    input_ = torch.randn(1,1,124,124)\n",
    "    output = model(input_)\n",
    "    output.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讓我們自行搭建一個 nn.Module 並試算gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.x = torch.nn.Parameter(torch.tensor(2.4,dtype=torch.float32))\n",
    "        self.y = torch.nn.Parameter(torch.tensor(4.3,dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x*self.x**2 + x*self.y + x # 可以看成 output = w*x*x + w*y+2\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.x 的 gradient : 6.240000247955322\n",
      "self.y 的 gradient : 1.2999999523162842\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "input_ = torch.tensor(1.3, dtype = torch.float32)\n",
    "output = model(input_)\n",
    "output.backward()\n",
    "# output 對 self.x 的偏微分為 2 * w * x = 2 * 1.3 * 2.4 = 6.24 \n",
    "print('self.x 的 gradient : {}'.format(model.x.grad))\n",
    "# output 對 self.y 的偏微分為 w = 1.3\n",
    "print('self.y 的 gradient : {}'.format(model.y.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential\n",
    "* nn.Module 的容器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Sequential(\n",
    "                        nn.Conv2d(3,\n",
    "                                  20,\n",
    "                                  kernel_size=3,\n",
    "                                  stride=1,\n",
    "                                  padding=1,\n",
    "                                  bias=False), \n",
    "                        nn.BatchNorm2d(20),\n",
    "                        nn.LeakyReLU(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight True\n",
      "1.weight True\n",
      "1.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in layer.named_parameters():\n",
    "    print(name,param.requires_grad)\n",
    "    #param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.randn(1, 3, 124, 124)\n",
    "output = layer(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OrderedDict+Sequential, 讓我們替每一個module命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      ")\n",
      "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "ReLU()\n",
      "Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "ReLU()\n"
     ]
    }
   ],
   "source": [
    "for module in layer.modules():\n",
    "    print(module)\n",
    "    #param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight True\n",
      "conv1.bias True\n",
      "conv2.weight True\n",
      "conv2.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in layer.named_parameters():\n",
    "    print(name,param.requires_grad)\n",
    "    #param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 124, 124)\n",
    "output = layer(input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### append 新的 module到 sequential上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "modules = []\n",
    "modules.append(nn.Conv2d(1,20,5))\n",
    "modules.append(nn.ReLU())\n",
    "modules.append(nn.Conv2d(20,64,5))\n",
    "modules.append(nn.ReLU())\n",
    "\n",
    "layer = nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 124, 124)\n",
    "output = layer(input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 另一種方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = torch.nn.Sequential()\n",
    "layer.add_module(\"conv1\", nn.Conv2d(1,20,5))\n",
    "layer.add_module(\"relu1\", nn.ReLU())\n",
    "layer.add_module(\"conv2\", nn.Conv2d(20,64,5))\n",
    "layer.add_module(\"relu2\", nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 124, 124)\n",
    "output = layer(input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModuleList\n",
    "* 操作就像是python list, 但其內的module, parameters是可以被追蹤的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.ModuleList()\n",
    "layer.append(nn.Conv2d(1,20,5))\n",
    "layer.append(nn.ReLU())\n",
    "layer.append(nn.Conv2d(20,64,5))\n",
    "layer.append(nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 124, 124)\n",
    "for _, module in enumerate(layer):\n",
    "    if _ == 0:\n",
    "        output = module(input_)\n",
    "    else:\n",
    "        output = module(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以追蹤是什麼意思？ nn.Module有辦法去獲取ModuleList裡面的資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer = nn.ModuleList()\n",
    "        self.layer.append(nn.Conv2d(1,20,5))\n",
    "        self.layer.append(nn.ReLU())\n",
    "        self.layer.append(nn.Conv2d(20,64,5))\n",
    "        self.layer.append(nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for module in self.layer:\n",
    "            x = module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer): ModuleList(\n",
       "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 116, 116])\n"
     ]
    }
   ],
   "source": [
    "input_ = torch.randn(1, 1, 124, 124)\n",
    "output = model(input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如果是一般的 python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer = []\n",
    "        self.layer.append(nn.Conv2d(1,20,5))\n",
    "        self.layer.append(nn.ReLU())\n",
    "        self.layer.append(nn.Conv2d(20,64,5))\n",
    "        self.layer.append(nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for module in self.layer:\n",
    "            x = module(x)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model()"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
